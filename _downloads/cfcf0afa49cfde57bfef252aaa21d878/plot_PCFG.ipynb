{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Abstracted PCFGs\n\nThis is an example of defining a simple discrete RBN equivalent to a PCFG using the :class:`AbstractedPCFG\n<rbnet.pcfg.AbstractedPCFG>` class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from rbnet.pcfg import AbstractedPCFG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Minimal Example\nWe start with a minimal example (also used in :doc:`/auto_examples/plot_discrete_RBN`):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pcfg = AbstractedPCFG(non_terminals=\"SAB\", terminals=\"ab\", start=\"S\", rules=[\n    (\"S --> A B\", 1), (\"S --> B A\", 1),  # prior + first transition\n    (\"A --> B A\", 1), (\"B --> A B\", 1),  # non-terminal transitions\n    (\"A --> a\", 1), (\"B --> b\", 1)       # terminal transition\n])\n\nprint(pcfg.inside(sequence=\"aaaa\"))\nprint(pcfg.inside(sequence=\"bbbb\"))\nprint(pcfg.inside(sequence=\"aaab\"))\nprint(pcfg.inside_chart[0].pretty())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the PCFG\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we define a number of words (terminal symbols) of different categories that sentences can be composed of:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subjects = [\"I\", \"You\", \"We\", \"They\"]\nverbs = [\"run\", \"drink\", \"sleep\"]\nadverb_non_gradable = [\"a-lot\", \"alone\"]\nadverb_gradable = [\"fast\", \"slowly\", \"quickly\"]\ngrade = [\"very\", \"veeery\", \"really\"]\nverb_qualifier = [\"rarely\", \"do-not\", \"never\", \"always\"]\nterminals = subjects + verbs + adverb_non_gradable + adverb_gradable + grade + verb_qualifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we define some non-terminal symbols (a start symbol and one symbol for each category of words used above):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "non_terminals = [\"start\",\n                 \"subject\",\n                 \"verb\",\n                 \"gradable_adverb\",\n                 \"non_gradable_adverb\",\n                 \"verb_qualifier\",\n                 \"grade\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we define the rules and give them a weight (for simplicity we use a weight of 1 everywhere):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "non_terminal_rules = [(\"start --> subject verb\", 1),\n                      (\"verb --> verb_qualifier verb\", 1),\n                      (\"verb --> verb gradable_adverb\", 1),\n                      (\"verb --> verb non_gradable_adverb\", 1),\n                      (\"gradable_adverb --> grade gradable_adverb\", 1),\n                      (\"grade --> grade grade\", 1)]\nterminal_rules = []\nfor non_terminal_symbol, corresponding_list_of_terminal_symbols in zip(\n        non_terminals[1:],  # skip the start symbol\n        [subjects, verbs, adverb_gradable, adverb_non_gradable, verb_qualifier, grade]\n):\n    for terminal_symbol in corresponding_list_of_terminal_symbols:\n        terminal_rules.append((f\"{non_terminal_symbol} --> {terminal_symbol}\", 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can define our PCFG by providing it with the terminals, non-terminals, rules, and start symbol.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pcfg = AbstractedPCFG(terminals=terminals,\n                      non_terminals=non_terminals,\n                      rules=non_terminal_rules + terminal_rules,\n                      start=\"start\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parsing Sentences\nLet's test the grammar by computing the marginal likelihood of some grammatical sentences\n(which should be greater than zero) and for some un-grammatical ones (which should have zero marginal likelihood)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grammatical_sentences = [\n    \"I run\",\n    \"You never run\",\n    \"We run very veeery slowly\",\n    \"They always run alone\",\n    \"I never sleep really very quickly\",\n    \"You do-not drink very quickly\"]\nungrammatical_sentences = [\n    \"I You\",\n    \"run fast\"\n]\nfor sentence in grammatical_sentences + ungrammatical_sentences:\n    marginal_likelihood = pcfg.inside(sequence=sentence.split())\n    print(f\"{sentence} --> {marginal_likelihood}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also print a simple textual visualisation of the parse chart, which shows\n``non-terminal symbol|inside probability`` at each location\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pcfg.inside(sequence=\"You never run\".split())\nprint(pcfg.map_inside_chart(precision=2).pretty())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Parameters\nFor a given dataset of sentences, we can train the model parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\nimport torch\nimport numpy as np\nfrom rbnet.util import SequenceDataModule\n\nprint(pcfg)\npcfg.auto_tokenise = False\n# pcfg.cells[0].variable.chart_type = \"dict\"\ndata = SequenceDataModule([pcfg.tokenise(s.split()) for s in grammatical_sentences], val_split=0, test_split=0)\ndata.setup()\n\n# for batch in data.train_dataloader():\n#     print(batch[0])\n#     print(pcfg.inside(batch[0]))\n#\n# for s in grammatical_sentences:\n#     s = pcfg.tokenise(s.split())\n#     print(s)\n#     print(pcfg.inside(s))\n\n# print(list(pcfg.parameters()))\n\n\n\n# trainer = pl.Trainer(max_epochs=100)\n# trainer.fit(pcfg, data.train_dataloader())\n#\n# print(list(pcfg.parameters()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}